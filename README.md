# ğŸŒ Web Diver

**Web Diver** Ã© uma ferramenta simples e poderosa de *web crawling* e automaÃ§Ã£o de buscas na **World Wide Web**, desenvolvida em Python. O objetivo principal do Web Diver Ã© realizar a leitura e arquivamento de conteÃºdos de URLs especÃ­ficas, salvando os dados de forma estruturada em um banco de dados SQLite local.

---

## ğŸš€ InstalaÃ§Ã£o

Antes de tudo, certifique-se de estar utilizando **Python 3.6+** e ter o `pip` atualizado.

### Instale via pip:
```bash
pip install webdiver_v1

pip install requests beautifulsoup4 pandas

âš™ï¸ Funcionalidades BÃ¡sicas
set_task_uri(url: str)
Define a URL que serÃ¡ utilizada na tarefa de leitura e busca de conteÃºdo na web.

Exemplo:

set_task_uri("https://example.com")

www_diver()
Executa a leitura da URL definida com set_task_uri() e armazena as informaÃ§Ãµes extraÃ­das no banco de dados SQLite.

Exemplo:

www_diver()

sql_setup(db_name: str)
Cria e configura um arquivo .db para manter os registros das pesquisas realizadas pelo Web Diver.

Exemplo:

sql_setup("webdiver_archive.db")

set_task(uri: str, hour: int, minute: int)
Agenda uma nova tarefa de web crawling para um horÃ¡rio especÃ­fico, definindo a URL, a hora e o minuto da execuÃ§Ã£o automÃ¡tica.

Exemplo:

set_task("https://example.com/news", 14, 30)

ğŸ’¡ Exemplos de Uso

from webdiver import set_task_uri, www_diver, sql_setup, set_task

sql_setup("mydata.db")
set_task_uri("https://example.com")
www_diver()

# Agendamento de tarefa
set_task("https://example.com", 12, 45)

ğŸ—ƒï¸ Banco de Dados
Os dados capturados sÃ£o armazenados automaticamente em um banco SQLite com informaÃ§Ãµes como:

URL acessada

ConteÃºdo HTML simplificado

Timestamp da coleta

ğŸ‘¨â€ğŸ’» Desenvolvido por
#asytrick
Projeto disponÃ­vel em: github.com/ssmool/webdiver
